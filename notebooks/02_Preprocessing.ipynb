{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e6ddae",
   "metadata": {},
   "source": [
    "## Preprocessing Notebook\n",
    "\n",
    "This notebook implements the preprocessing pipeline for the dataset. To ensure efficiency and minimize runtime, intermediate results are saved into files (e.g., pickle files). This approach allows for quicker re-execution and avoids redundant computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdeb32",
   "metadata": {},
   "source": [
    "### Cell 1: Import Libraries\n",
    "\n",
    "**Purpose:** This cell imports the required libraries for data preprocessing, analysis, and file management."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac80b465-1e6c-4960-abe8-66177ec279a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:37:00.196997Z",
     "start_time": "2025-02-03T10:37:00.169891Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import Audio, display"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "0ba6863d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 2: Set Directory Paths\n",
    "\n",
    "**Purpose:** This cell defines the paths for accessing raw and processed data files."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:37:23.105458Z",
     "start_time": "2025-02-03T10:37:23.069649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Function to automatically find the project root directory\n",
    "def find_project_root():\n",
    "    current_path = Path(os.getcwd()).resolve()\n",
    "    while current_path != current_path.parent:  # Ensures we don't go beyond the system root\n",
    "        if (current_path / \"config.py\").exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(\"⚠️ config.py not found! Make sure it is in the project root directory.\")\n",
    "\n",
    "# Determine the project root directory\n",
    "project_root = find_project_root()\n",
    "\n",
    "# Add the project root to Python's search path (if it's not already there)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Reload config.py to ensure that any changes are updated\n",
    "import config\n",
    "importlib.reload(config)\n"
   ],
   "id": "9219dab3015fb6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\Users\\\\יהונתן רבוח\\\\OneDrive - Holon Institute of Technology\\\\Deep Learning Project\\\\config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:39:22.793187Z",
     "start_time": "2025-02-03T10:39:22.785576Z"
    }
   },
   "cell_type": "code",
   "source": "from config import AUDIO_FILES_PATH, CSV_FILE_PATH, PROCESSED_DATA_DIR",
   "id": "94c59959226a4423",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c306da02-bcdf-4e8a-9ca8-7133dc2783cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:37:53.431154Z",
     "start_time": "2025-02-03T10:37:53.414212Z"
    }
   },
   "source": "df = pd.read_csv(CSV_FILE_PATH)",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "30159381",
   "metadata": {},
   "source": [
    "### Cell 4:\n",
    "\n",
    "**Purpose:** This cell performs a specific preprocessing or transformation task."
   ]
  },
  {
   "cell_type": "code",
   "id": "b768260c-2a90-4f4d-bc2e-ea42e7c6f856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:38:05.772774Z",
     "start_time": "2025-02-03T10:38:05.763658Z"
    }
   },
   "source": [
    "def generate_log_mel_spectrogram(file_path, sr=None, n_mels=128, hop_length=512):\n",
    "    \"\"\"Generate Log Mel-Spectrogram from an audio file.\"\"\"\n",
    "    signal, sr = librosa.load(file_path, sr=sr)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "    log_mel = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return log_mel"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a0bf00eb",
   "metadata": {},
   "source": [
    "### Cell 5: Set Directory Paths\n",
    "\n",
    "**Purpose:** This cell defines the paths for accessing raw and processed data files."
   ]
  },
  {
   "cell_type": "code",
   "id": "b65da231-6ca2-44fd-9817-cbb15fcc0539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:38:09.390578Z",
     "start_time": "2025-02-03T10:38:09.380295Z"
    }
   },
   "source": [
    "def save_spectrogram(spectrogram, category, filename, output_dir=\"processed_spectrograms\"):\n",
    "    \"\"\"Save spectrograms to disk for later visualization.\"\"\"\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    np.save(os.path.join(category_dir, f\"{filename}.npy\"), spectrogram)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "01ed1b53",
   "metadata": {},
   "source": [
    "### Cell 6: Pad Spectrogram to Fixed Length\n",
    "\n",
    "**Purpose**: This function ensures that spectrograms are uniformly sized by either padding them with zeros or truncating them to a specified target length. This standardization is essential for processing spectrograms in machine learning models, which typically require inputs of consistent dimensions."
   ]
  },
  {
   "cell_type": "code",
   "id": "df9baca5-3306-4389-84e4-ded2b2f25c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:05.128696Z",
     "start_time": "2025-02-03T10:41:05.118633Z"
    }
   },
   "source": [
    "def pad_spectrogram(spectrogram, target_length=500):\n",
    "    \"\"\"Pad spectrograms to a fixed length.\"\"\"\n",
    "    if spectrogram.shape[1] < target_length:\n",
    "        pad_width = target_length - spectrogram.shape[1]\n",
    "        return np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        return spectrogram[:, :target_length]\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "0292f136",
   "metadata": {},
   "source": [
    "### Cell 7: Normalize Spectrogram\n",
    "\n",
    "**Purpose:** This function normalizes a spectrogram by adjusting its values to have a mean of 0 and a standard deviation of 1. Normalization helps improve the performance and stability of machine learning models by standardizing the input data."
   ]
  },
  {
   "cell_type": "code",
   "id": "a36e57bd-bf42-475c-a1e3-a11a242c1a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:07.565198Z",
     "start_time": "2025-02-03T10:41:07.556753Z"
    }
   },
   "source": [
    "def normalize_spectrogram(spectrogram):\n",
    "    return (spectrogram - np.mean(spectrogram)) / np.std(spectrogram)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8c4b2c-e394-4b61-98e9-3604919d945d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:51:30.274296Z",
     "start_time": "2025-01-08T20:51:30.267401Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79457277",
   "metadata": {},
   "source": [
    "# Cell 8: Resize Spectrogram to Target Shape\n",
    "\n",
    "**Purpose:** This function resizes a spectrogram to a specified target shape using OpenCV's interpolation. Resizing is crucial for standardizing input dimensions, ensuring compatibility with machine learning models that require fixed input sizes. The interpolation method used (INTER_AREA) is suitable for downscaling, preserving the quality of the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e4fe086-3989-4484-8d6f-1319e838e69d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:12.555787Z",
     "start_time": "2025-02-03T10:41:10.290356Z"
    }
   },
   "source": [
    "import cv2\n",
    "\n",
    "def resize_spectrogram(spectrogram, target_shape=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize a spectrogram to the target shape using OpenCV.\n",
    "\n",
    "    Parameters:\n",
    "    - spectrogram: Input spectrogram (2D numpy array).\n",
    "    - target_shape: Desired shape (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - Resized spectrogram.\n",
    "    \"\"\"\n",
    "    resized = cv2.resize(spectrogram, target_shape, interpolation=cv2.INTER_AREA)\n",
    "    return resized\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "5d3d48d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 9: Save Preprocessed Spectrogram Data\n",
    "\n",
    "**Purpose:** This function saves a processed spectrogram into a structured directory. Each spectrogram is stored in a subdirectory corresponding to its category, ensuring organized storage for efficient retrieval. The processed spectrogram is saved as a NumPy array with a filename indicating it has been processed. This approach facilitates systematic management of preprocessed data for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "id": "962f62a1-c03b-46fb-8e56-45a3555fc128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:15.268255Z",
     "start_time": "2025-02-03T10:41:15.261156Z"
    }
   },
   "source": [
    "def save_preprocessed_data(spectrogram, category, filename, output_dir=\"processed_data\"):\n",
    "    \"\"\"Save processed spectrogram in a structured directory.\"\"\"\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    np.save(os.path.join(category_dir, f\"{filename}_processed.npy\"), spectrogram)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "c257b149",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 10: Process and Save Audio File Spectrograms\n",
    "\n",
    "**Purpose:** This function processes an audio file by generating, normalizing, padding, resizing, and saving its spectrogram for both visualization and model input, ensuring efficient reuse and structured storage."
   ]
  },
  {
   "cell_type": "code",
   "id": "57217d05-b8d2-4613-90a6-efc43782c3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:17.473744Z",
     "start_time": "2025-02-03T10:41:17.461421Z"
    }
   },
   "source": [
    "def process_audio_file(file_path, category, filename, output_dir, spectrogram_dir):\n",
    "    \"\"\"\n",
    "    Process an audio file:\n",
    "    - Generate and save spectrogram for visualization if it doesn't already exist.\n",
    "    - Apply padding, normalization, and resizing for model input if not already processed.\n",
    "    \"\"\"\n",
    "    raw_spectrogram_path = os.path.join(spectrogram_dir, category, f\"{filename}.npy\")\n",
    "    processed_spectrogram_path = os.path.join(output_dir, category, f\"{filename}_processed.npy\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(raw_spectrogram_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(processed_spectrogram_path), exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(raw_spectrogram_path):\n",
    "        spectrogram = generate_log_mel_spectrogram(file_path)\n",
    "        spectrogram = normalize_spectrogram(spectrogram)\n",
    "        np.save(raw_spectrogram_path, spectrogram)\n",
    "    else:\n",
    "        spectrogram = np.load(raw_spectrogram_path)\n",
    "    \n",
    "    if not os.path.exists(processed_spectrogram_path):\n",
    "\n",
    "        spectrogram = pad_spectrogram(spectrogram)\n",
    "        print(f\"After padding: {spectrogram.shape}\")\n",
    "        \n",
    "        spectrogram = resize_spectrogram(spectrogram, target_shape=(128, 128))\n",
    "        print(f\"After resizing: {spectrogram.shape}\")\n",
    "        \n",
    "        np.save(processed_spectrogram_path, spectrogram)\n",
    "    \n",
    "    return spectrogram\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "30065807",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 11: Batch Process Audio Files\n",
    "\n",
    "**Purpose:** This function processes multiple audio files by generating and saving raw and processed spectrograms, ensuring structured storage and avoiding redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "id": "7a9549ee-75c8-4a32-919a-cb9256581a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:20.715734Z",
     "start_time": "2025-02-03T10:41:20.705222Z"
    }
   },
   "source": [
    "def batch_process_audio_files(df, audio_dir, output_dir, spectrogram_dir):\n",
    "    \"\"\"\n",
    "    Batch process all audio files:\n",
    "    - Save raw spectrograms in spectrogram_dir only if they don't already exist.\n",
    "    - Save processed spectrograms in output_dir only if they don't already exist.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        file_path = os.path.join(audio_dir, row['filename'])\n",
    "        category = row['category']\n",
    "        filename = os.path.splitext(row['filename'])[0]\n",
    "        process_audio_file(file_path, category, filename, output_dir, spectrogram_dir)\n",
    "    print(f\"All files processed and saved in {output_dir} and {spectrogram_dir}\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "75c4bfb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 12: Execute Batch Audio File Processing\n",
    "\n",
    "**Purpose:** This cell processes all audio files in the dataset by generating and saving raw and processed spectrograms into structured directories for efficient storage and reuse."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a4b3639-5c3d-4764-8af3-80ab7a129479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:41:27.393610Z",
     "start_time": "2025-02-03T10:41:24.156092Z"
    }
   },
   "source": [
    "PROCESSED_DATA_PATH = os.path.join(PROCESSED_DATA_DIR,'processed_data')\n",
    "PROCESSED_SPECTOGRAMS_PATH = os.path.join(PROCESSED_DATA_DIR,'processed_spectrograms')\n",
    "\n",
    "batch_process_audio_files(df, audio_dir=AUDIO_FILES_PATH,output_dir=PROCESSED_DATA_PATH, spectrogram_dir=PROCESSED_SPECTOGRAMS_PATH)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed and saved in C:\\Users\\יהונתן רבוח\\OneDrive - Holon Institute of Technology\\Deep Learning Project\\data\\processed\\processed_data and C:\\Users\\יהונתן רבוח\\OneDrive - Holon Institute of Technology\\Deep Learning Project\\data\\processed\\processed_spectrograms\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "b4f46a3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 13: Verify Saved Spectrograms\n",
    "\n",
    "**Purpose:** This function checks that all saved spectrograms in a given directory match the expected shape. It identifies and lists any files with mismatched dimensions to ensure data consistency for downstream processing or modeling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f66a400b63415d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T19:34:19.400709Z",
     "start_time": "2025-01-11T19:34:17.684445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All spectrograms have the expected shape!\n"
     ]
    }
   ],
   "source": [
    "def verify_saved_spectrograms(directory, expected_shape=(128, 128)):\n",
    "    mismatched = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".npy\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                spectrogram = np.load(file_path)\n",
    "                #print(f\"Checking file: {file_path}, Shape: {spectrogram.shape}\")  # Debug\n",
    "                if spectrogram.shape != expected_shape:\n",
    "                    mismatched.append((file, spectrogram.shape))\n",
    "\n",
    "    if mismatched:\n",
    "        print(f\"Found {len(mismatched)} mismatched files:\")\n",
    "        for file, shape in mismatched:\n",
    "            print(f\"{file}: {shape}\")\n",
    "    else:\n",
    "        print(\"All spectrograms have the expected shape!\")\n",
    "\n",
    "\n",
    "\n",
    "verify_saved_spectrograms(PROCESSED_DATA_PATH, expected_shape=(128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a56c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 14: Add Gaussian Noise to Audio Signal\n",
    "\n",
    "**Purpose:** This function applies Gaussian noise to an audio signal, simulating real-world conditions or augmenting data for improved model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d25cb-ae80-41b4-98c7-72da10b0f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(signal, noise_factor=0.005):\n",
    "    \"\"\"Add Gaussian noise to the audio signal.\"\"\"\n",
    "    noise = np.random.normal(0, noise_factor, signal.shape)\n",
    "    return signal + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c7ef1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 15: Apply Time Stretching to Audio Signal\n",
    "\n",
    "**Purpose:** This function modifies the duration of an audio signal without altering its pitch by applying time stretching using Librosa's phase vocoder, which is useful for data augmentation and audio processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98406407-f5f2-4348-9361-6944dcf548a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, rate=1.2, sr=22050):\n",
    "    \"\"\"\n",
    "    Apply time stretching to the audio signal using librosa.phase_vocoder.\n",
    "    \"\"\"\n",
    "    # Ensure the input signal is long enough\n",
    "    if len(signal) < sr:  # Less than 1 second\n",
    "        raise ValueError(\"Signal too short for time-stretching.\")\n",
    "    \n",
    "    # Compute the Short-Time Fourier Transform (STFT)\n",
    "    hop_length = 512  # Standard hop length\n",
    "    stft = librosa.stft(signal, hop_length=hop_length)\n",
    "    \n",
    "    # Apply time stretching using phase vocoder\n",
    "    stretched_stft = librosa.phase_vocoder(stft, rate=rate, hop_length=hop_length)\n",
    "    \n",
    "    # Convert back to waveform\n",
    "    stretched_signal = librosa.istft(stretched_stft, hop_length=hop_length)\n",
    "    \n",
    "    return stretched_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadedcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 16: Apply Pitch Shifting to Audio Signal\n",
    "**Purpose:** This function alters the pitch of an audio signal by a specified number of semitones without affecting its duration. It is commonly used for data augmentation and pitch-related analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4c191-52fa-424d-8b24-9096c844c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(signal, sr, n_steps=2):\n",
    "    \"\"\"\n",
    "    Apply pitch shifting to the audio signal.\n",
    "    \"\"\"\n",
    "    return librosa.effects.pitch_shift(y=signal, sr=sr, n_steps=n_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eab9f0",
   "metadata": {},
   "source": [
    "### Cell 17: Apply Random Audio Augmentation\n",
    "**Purpose:** This function applies a randomly chosen augmentation (e.g., noise addition, time stretching, or pitch shifting) to an audio signal, enhancing data diversity for training machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5660fc6-53e3-4c35-9525-66615a0e9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_augmentation(signal, sr):\n",
    "    \"\"\"\n",
    "    Apply a random audio augmentation to the signal.\n",
    "    \"\"\"\n",
    "    augmentations = [\n",
    "        lambda x: add_noise(x, noise_factor=0.005),  # Add noise\n",
    "        lambda x: time_stretch(x, rate=random.uniform(0.8, 1.2), sr=sr),  # Time stretch\n",
    "        lambda x: pitch_shift(x, sr, n_steps=random.randint(-2, 2))  # Pitch shift\n",
    "    ]\n",
    "    # Randomly select an augmentation\n",
    "    augmentation = random.choice(augmentations)\n",
    "    return augmentation(signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cdc405",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 18: Generate Random Augmentations for Audio Files\n",
    "**Purpose:** This function creates a random number of augmented spectrograms for a given audio file. It applies random audio augmentations, generates log-mel spectrograms, normalizes them, and saves the augmented results in a structured directory for further use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d7b9a-2935-447c-9ceb-ef78303ab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_augmentations(file_path, category, filename, output_dir=\"augmented_data\", min_augment=1, max_augment=5):\n",
    "    \"\"\"\n",
    "    Generate a random number of augmented spectrograms for a given file.\n",
    "    \"\"\"\n",
    "    # Create a directory for the category if it doesn't exist\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "\n",
    "    # Decide the number of augmentations\n",
    "    num_augmentations = random.randint(min_augment, max_augment)\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        # Load the audio file\n",
    "        signal, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Apply a random augmentation\n",
    "        augmented_signal = apply_random_augmentation(signal, sr)\n",
    "        \n",
    "        # Generate Log Mel spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=augmented_signal, sr=sr, n_mels=128, hop_length=512)\n",
    "        augmented_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        \n",
    "        # Pad and resize the spectrogram\n",
    "        augmented_spectrogram_resized = cv2.resize(augmented_spectrogram, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Normalization the spectogram\n",
    "        normalized_spectrogram = (augmented_spectrogram_resized - np.min(augmented_spectrogram_resized)) / \\\n",
    "                                 (np.max(augmented_spectrogram_resized) - np.min(augmented_spectrogram_resized))\n",
    " \n",
    "  \n",
    "        # Save the augmented spectrogram\n",
    "        augmented_filename = f\"{filename}_aug_{i}.npy\"    \n",
    "        np.save(os.path.join(category_dir, augmented_filename),\n",
    "                {\"spectrogram\": normalized_spectrogram,\n",
    "                 \"min\": np.min(augmented_spectrogram_resized),\n",
    "                 \"max\": np.max(augmented_spectrogram_resized) })\n",
    "    print(f\"Generated {num_augmentations} augmented files for {filename} in {category}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01686b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 19: Batch Generate Augmentations for Dataset\n",
    "**Purpose:** This function applies random augmentations to all audio files in the dataset, generating multiple augmented spectrograms for each file and saving them in a structured directory to enhance data diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1e1fb-08bd-49f1-ac60-f2ad31c17abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process augmentations\n",
    "def batch_generate_augmentations(df, audio_dir, output_dir=\"augmented_data\", min_augment=1, max_augment=5):\n",
    "    \"\"\"\n",
    "    Generate augmented spectrograms for all audio files in the dataset.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        file_path = os.path.join(audio_dir, row['filename'])\n",
    "        category = row['category']\n",
    "        filename = os.path.splitext(row['filename'])[0]\n",
    "        generate_random_augmentations(file_path, category, filename, output_dir, min_augment, max_augment)\n",
    "\n",
    "    print(f\"Augmented data saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98639cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 20: Run Batch Augmentation for Audio Files\n",
    "**Purpose:** This cell executes the batch augmentation process, generating and saving multiple augmented spectrograms for each audio file in a structured directory to enhance the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "id": "5345e726-c384-4e1e-948d-fda62a248823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:42:02.523054Z",
     "start_time": "2025-02-03T10:42:02.514849Z"
    }
   },
   "source": [
    "# Run batch augmentation\n",
    "AUGMENTED_DATA_PATH = os.path.join(PROCESSED_DATA_DIR, 'augmented_data')\n",
    "\n",
    "#batch_generate_augmentations(df, audio_dir=AUDIO_FILES_PATH,output_dir=AUGMENTED_DATA_PATH)\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "5d81a69e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 21: Play Augmented Audio Sample\n",
    "**Purpose:** This function selects and plays a randomly chosen augmented audio sample from a specified category. It denormalizes the saved spectrogram, converts it back to an audio signal, and plays it for inspection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfecccc-43d0-483d-9720-d10d0cfebaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_augmented_sample(category, filename, output_dir=\"augmented_data\"):\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    augmented_files = [f for f in os.listdir(category_dir) if filename in f]\n",
    "    if not augmented_files:\n",
    "        print(f\"No augmented files found for {filename} in category {category}.\")\n",
    "        return\n",
    "    \n",
    "    selected_file = np.random.choice(augmented_files)\n",
    "    augmented_path = os.path.join(category_dir, selected_file)\n",
    "    \n",
    "    # Load normalized spectrogram and normalization parameters\n",
    "    data = np.load(augmented_path, allow_pickle=True).item()\n",
    "    normalized_spectrogram = data[\"spectrogram\"]\n",
    "    min_val = data[\"min\"]\n",
    "    max_val = data[\"max\"]\n",
    "    \n",
    "    # Denormalize\n",
    "    spectrogram = normalized_spectrogram * (max_val - min_val) + min_val\n",
    "    \n",
    "    # Convert back to audio\n",
    "    signal = librosa.feature.inverse.mel_to_audio(\n",
    "        librosa.db_to_power(spectrogram), sr=22050, hop_length=512\n",
    "    )\n",
    "    \n",
    "    print(f\"Playing: {selected_file}\")\n",
    "    display(Audio(signal, rate=22050))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139bdc0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cell 22: Play a Specific Augmented Audio Sample\n",
    "**Purpose:** This cell plays a specific augmented audio sample from the dataset by retrieving its spectrogram, denormalizing it, and converting it back to an audio signal for playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99aa80-a700-4bb4-970a-430ad319e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_augmented_sample(category=\"dog\", filename=\"3-155312-A-0_aug_1\", output_dir=AUGMENTED_DATA_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
